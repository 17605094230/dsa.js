= Eight Running Times You Should Know

There are many kinds of algorithms. Most of them falls into one of the time complexities that we are going to explore in this chapter.

.Most common time complexities
- Constant time: _O(1)_
- Logarithmic time: _O(log n)_
- Linear time: _O(n)_
- Linearithmic time: _O(n log n)_
- Quadratic time: _O(n^2^)_
- Cubic time: _O(n^3^)_
- Exponential time: _O(2^n^)_
- Factorial time: _O(n!)_

We a going to provide examples for each one of them.

Before we dive in, here‚Äôs a plot with all of them.

.CPU operations vs Algorithm runtime as the input size grows
image:image5.png[CPU time needed vs Algorithm runtime as the input size grows]

This graph shows how the algorithm running time affects the CPU work as the input size grows. As you can see O(1) and O(log n) are very scalable. However, O(n^2^) and worst can make your computer burn [big]#üî•# on large data sets. We are going to give some examples so you can identify each one.

== Constant

Represented as *O(1)*, it means that regardless of the input size the number of operations executed is always the same. Let‚Äôs see an example

[#constant-example]
=== Finding if an array is empty

Let's implement a function that find out if an array is empty or not.

//.is-empty.js
//image:image6.png[image,width=528,height=401]

[source, javascript]
----
include::{codedir}/runtimes/01-is-empty.js[tag=isEmpty]
----

As you can see if thing is an array of 10 elements or an array of 10M elements it would take the same amount of time to execute. It doesn‚Äôt get any more performant than this!

== Logarithmic

Represented in Big O notation as *O(log n)*, when an algorithms has this running time it means that as the size of the input grows the number of operations grows very slowly. This make this kind of algorithms very scalable. One example is the *binary search*.

[#logarithmic-example]
=== Searching on a sorted array

The binary search only works for sorted lists. It starts searching for an element on the middle and then moves to the right or left depending if the value you are looking for is bigger or smaller.

// image:image7.png[image,width=528,height=437]

[source, javascript]
----
include::{codedir}/runtimes/02-binary-search.js[tag=binarySearchRecursive]
----

This is a recursive algorithm, which means that the function `binarySearch` calls itself multiple times until the solution is found. The binary search split the array in half every time.

Finding the runtime of recursive algorithms is not very obvious sometimes. It requires some intuition and following what the program is doing. The `binarySearch` divides the input in half each time. As a rule of thumb, when we have an algorithm that divides the input in half on each call we can say that has a logarithmic runtime: _O(log n)_.

== Linear

This is one of the most commons. It‚Äôs represented as *O(n)*. Usually an algorithm has a linear running time when it iterates over all the elements in the input.

[#linear-example]
=== Finding duplicates in an array using a map

Let‚Äôs say that we want to find duplicate elements in an array. What‚Äôs the first implementation that comes to mind? Check out this implementation:

// image:image8.png[image,width=528,height=383]

[source, javascript]
----
include::{codedir}/runtimes/03-has-duplicates.js[tag=hasDuplicates]
----

.`hasDuplicates` has multiple scenarios:
* *Best-case scenario*: first two elements are duplicates. It only has to visit two elements.
* *Worst-case scenario*: no duplicates or duplicates are the last two. In either case it has to visit every element on the array.
* *Average-case scenario*: duplicates are somewhere in the middle of the array. Only, half of the array has be visited.

As we learned before, the big O cares about the worst-case scenario, where we would have to visit every element on the array. So, we have an *O(n)* runtime.

Space complexity is also *O(n)* since we have a map that in the worst case (no duplicates) it will hold every word.

== Linearithmic

An algorithm with a linearithmic runtime is represented as _O(n log n)_. This one is important because is the best runtime for sorting! Let‚Äôs see the merge-sort.

[#linearithmic-example]
=== Sorting elements in an array

The merge sort, like its name indicates, has two functions merge and sort. Let‚Äôs start with the sort function:

// image:image9.png[image,width=528,height=383]

.Sort part of the mergeSort
[source, javascript]
----
include::{codedir}/runtimes/04-merge-sort.js[tag=sort]
----

Starting with the sort part, we basically divide the array in 2 halves and then merge them (line 16) recursively with the following function:

// image:image10.png[image,width=528,height=380]

.Merge part of the mergeSort
[source, javascript]
----
include::{codedir}/runtimes/04-merge-sort.js[tag=merge]
----


The merge function combines arrays in ascending order. Let‚Äôs say that we want to sort the array `[9, 2, 5, 1, 7, 6]`. In the following illustration you can see what each function does.

.Mergesort visualization. Shows the split, sort and merge steps
image:image11.png[Mergesort visualization,width=500,height=600]

How do we obtain the running time of the merge sort algorithm? The mergesort divides the array in half each time in the split phase, log n, and the merge function join each splits, n. The total work we have *O(n log n)*. There more formal ways to reach to this runtime like using the https://adrianmejia.com/blog/2018/04/24/analysis-of-recursive-algorithms/[Master Method] and https://www.cs.cornell.edu/courses/cs3110/2012sp/lectures/lec20-master/lec20.html[recursion trees].

== Quadratic

Running times that are quadratic, O(n^2^), are the ones to watch out for. They usually don‚Äôt scale well when they have large data to process.

Usually, they have double nested loops that where each one visits all or most elements in the input. One example of this is a na√Øve implementation to find duplicate words on an array.

[#quadratic-example]
=== Finding duplicates in an array (na√Øve approach)

If you remember we have solved this problem on the <<Linear, Linear>> section. We solved this problem before a O(n), let‚Äôs analyze this time with a O(n^2^):

// image:image12.png[image,width=527,height=389]

.Na√Øve implementation of has duplicates function
[source, javascript]
----
include::{codedir}/runtimes/05-has-duplicates-naive.js[tag=hasDuplicates]
----

As you can see, we have two nested loops causing the running time to be quadratic. How much different is a linear vs quadratic algorithm?

Let‚Äôs say you want to find duplicated phone number in a phone directory of a city (e.g. 1 million people). If you use this quadratic solution you would have to wait for ~12 days to get an answer [big]#üê¢#, while if you use the linear solution you will get the answer in seconds!


== Cubic

Cubic *O(n^3^)* and higher polynomial functions usually involves many nested loops. As an example of a cubic algorithm looks like let‚Äôs say you want to solve a multi-variable equation (using brute force):

[#cubic-example]
=== Solving a multi-variable equation

Let‚Äôs say we want to find the solution for this multi-variable equation:

_3x + 9y + 8z = 79_

A na√Øve approach to solve this will be the following program:

//image:image13.png[image,width=528,height=448]

.Na√Øve implementation of multi-variable equation solver
[source, javascript]
----
include::{codedir}/runtimes/06-multi-variable-equation-solver.js[tag=findXYZ]
----

WARNING: This just an example, there are better ways to solve multi-variable equations.

As you can see three nested loops usually translates to O(n^3^). If you have a 4 variable equation and four nested loops it would be O(n^4^) and so on. When we have a runtime in the form of _O(n^c^)_, where _c > 1_, we can refer as a *polynomial runtime*.

== Exponential

Exponential runtimes, O(2^n^), means that every time the input grows by 1 the amount of operations done by the algorithms doubles. Exponential programs are only usable for very small size of inputs (<100) otherwise it might not finish on your lifetime Ô∏è. Let‚Äôs do an example.

[#exponential-example]
=== Finding subsets of a set

Finding all distinct subsets of a given set.

// image:image14.png[image,width=528,height=401]

.Subsets in a Set
[source, javascript]
----
include::{codedir}/runtimes/07-sub-sets.js[tag=snippet]
----
<1> Base case is empty element.
<2> For each element from the input append it to the results array.
<3> The new results array will be what it was before + the duplicated with the appended element.

//.The way this algorithm generates all subsets is:
//1.  Base case is empty element (line 13). E.g. ['']
//2.  For each element from the input append it to the results array (line 16)
//3.  The new results array will be what it was before + the duplicated with the appended element (line 17)

Every time the input grows by one the size the result array doubles. That‚Äôs why it has an *O(2^n^)*.

== Factorial

Factorial runtime, O(n!), is not scalable at all. Even with input sizes of ~10 elements it will take a couple of seconds to compute. It‚Äôs that slow! [big]*üçØüêù*

.Factorial
****
A factorial, is the multiplication of all the numbers less than itself down to 1.

.For instance:
- 3! = 3 x 2 x 1 = 6
- 5! = 5 x 4 x 3 x 2 x 1 = 120
- 10! = 3,628,800
- 11! = 39,916,800
****

[#factorial-example]
=== Getting all permutations of a word

One classic example of an _O(n!)_ algorithm is finding all the different words that can be formed with a given set of letters.

.Word's permutations
// image:image15.png[image,width=528,height=377]
[source, javascript]
----
include::{codedir}/runtimes/08-permutations.js[tag=snippet]
----

As you can see in the `getPermutations` function, the resulting array is the factorial of the word length.

Factorial start very slow and then it quickly become unmanageable. A word size of just 11 characters would take a couple of hours in most computers!
[big]*ü§Ø*

== Summary

We went through 8 of the most common time complexities and provided examples for each of them. Hopefully, this will give you a toolbox to analyze algorithms in the while.

.Most common algorithmic running times and their examples
[cols="2,2,5",options="header"]
|===
|Big O Notation
|Name
|Example(s)

|O(1)
|<<Constant>>
|<<constant-example>>

|O(log n)
|<<Logarithmic>>
|<<logarithmic-example>>

|O(n)
|<<Linear>>
|<<linear-example>>

|O(n log n)
|<<Linearithmic>>
|<<linearithmic-example>>

|O(n^2^)
|<<Quadratic>>
|<<quadratic-example>>

|O(n^3^)
|<<Cubic>>
|<<cubic-example>>

|O(2^n^)
|<<Exponential>>
|<<exponential-example>>

|O(n!)
|<<Factorial>>
|<<factorial-example>>
|===
