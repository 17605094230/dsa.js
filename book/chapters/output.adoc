

= Graph Data Structure

Graphs is one of my favorite data structures. They have a lot of cool
applications and are used in more places than you can imagine. First,
let’s start with the basics.

A graph is a non-linear data structure where a node can have zero or
more linked nodes.

You can think of graph like an extension of a Linked List. Instead of
having only a next or previous linked node, you can have as many as you
want. Actually, you can an array of linked nodes.

/**

* Graph node/vertex that hold adjacencies nodes

*/

class Node \{

constructor(value) \{

this.value = value;

this.adjacents = []; // adjacency list

}

}

As you can see, it’s pretty similar to the Linked List node indeed. The
only difference is that uses an *array* of the linked nodes instead.

Other difference between a linked list and graph is that linked list
have a start/first/root node, while the graph doesn’t. You can start
traversing a graph from anywhere and there might be circular references
as well. Let’s study this graph properties!

== Graph Properties

The connection between two nodes is called *edge*. Also, nodes might be
called *vertex*.

image:extracted-media/media/image42.png[image,width=305,height=233]

Figure 26 - Graph is composed of vertices/nodes and edges

=== Directed Graph vs Undirected

A graph can *directed* and *undirected*.

image:extracted-media/media/image43.jpg[image,width=469,height=192]

Figure 27 - Graph: directed vs undirected

A *directed graph (digraph)* has edges that are *one-way street*. E.g.
On the directed example, you can only go from green node to orange and
not the other way around. When one node has an edge to itself is called
a *self-loop*.

An *undirected graph* has edges that are *two-way street*. E.g. On the
undirected example, you can traverse from the green node to the orange
and vice versa.

=== Graph Cycles

A graph can have *cycles* or not.

image:extracted-media/media/image44.jpg[image,width=444,height=194]

Figure 28 - Cyclic vs Acyclic Graphs.

A *cyclic graph* is the one that you can pass through a node more than.
E.g. On the cyclic illustration, if you start in the green node, then go
the orange and purple, finally, you could come back to green again.
Thus, it has a *cycle*.

All *undirected* graphs are cyclic but not all *directed* graphs are
cyclic.

An acyclic graph is the one that you can’t pass through a node more than
once. E.g. in the acyclic illustration, can you to find a path where you
can pass through the same vertex more than one?

*Directed Acyclic Graphs (DAG)* are also known as a *Tree* when each
node has only *one parent*.

=== Connected vs Disconnected vs Complete Graphs

image:extracted-media/media/image45.emf[image,width=528,height=176]

Figure 29 - Different kinds of graphs: disconnected, connected, and
complete.

A *disconnected graph* is one that have one or more subgraph. In other
words, a graph is *disconnected* if there are two nodes that doesn’t
have a path between them.

A *connected graph* is the opposite to disconnected, there’s a path
between every node.

A *complete graph* is where every node is adjacent to all the other
nodes in the graph. E.g. If there are 7 nodes, every node has 6 edges.

=== Weighted Graphs

Weighted graphs have labels in the edges. The label is called *weight*
or *cost*. The weight can represent many things like distance, travel
time, or anything else.

image:extracted-media/media/image46.png[image,width=528,height=337]

Figure 30 - Weighted Graph representing USA airports distance in miles.

For instance, a weighted graph can have the distance between nodes. So,
algorithms can use the weight and optimize the path between them.

== Exciting Graph applications in real-world

Now that we know what graphs are and some of their properties let’s
discuss about some real-life usages of graphs.

Graphs become a metaphor where nodes and edges model something from our
physical world. Just to name a few:

* Optimizing Plane traveling

* Nodes = Airport
* Edges = Direct flights between two airports
* Weight = miles between airports | cost | time

* GPS Navigation System

* Node = road intersection
* Edge = road
* Weight = time between intersections

* Network routing

* Node = server
* Edge = data link
* Weight = connection speed

There are endless applications for graphs in electronics, social
networks, recommendation systems and many more. That’s cool and all, but
how do we represent graphs in code? Let’s see that in the next section.

== Representing Graphs

There are two main ways to graphs one is:

* Adjacency Matrix
* Adjacency List

=== Adjacency Matrix

Representing graphs as adjacency matrix is done using a two-dimensional
array. For instance, let’s say we have the following graph:

image:extracted-media/media/image47.png[image,width=438,height=253]

Figure 31 - Graph and its adjacency matrix.

The size of the matrix is given by the number of vertices |V|, in the
example we have 5 vertices so we have a 5x5 matrix.

To fill up the matrix, we go row by row. Mark with 1 (or any other
weight) when you find an edge. E.g.

* Row 0: It has a self-loop, so it has a 1 in the intersection of 0,0.
The node 0 also has an edge to 1 and 4 so we mark it.
* Row 1: The node 1 has one edge to 3 so we mark it.
* Row 2: Node 2 goes to Node 4, so we mark the insertion with 1.
* And so on…

The example graph above is a directed graph (digraph). In case of
undirected graph, the matrix would be symmetrical by the diagonal.

If we represent the example graph in code, it would be something like
this:

_const_ digraph = [

[1, 1, 0, 0, 1],

[0, 0, 0, 1, 0],

[0, 0, 0, 0, 1],

[0, 0, 1, 0, 0],

[0, 1, 0, 0, 0],

];

It would be very easy to tell if two nodes are connected. Let’s query if
node 2 is connected to 3:

digraph[2][3]; _//=> 0_

digraph[3][2]; _//=> 1_

As you can see we don’t have a link from node 2 to 3, but we do in the
opposite direction. Querying arrays is constant time *O(1)*, so no bad
at all.

The issue with the adjacency matrix is the space it takes. Let’s say you
want to represent the entire Facebook network on a digraph. You would
have a huge matrix of 1.2 billion x 1.2 billion. The worst part is that
most of it would be empty (zeros) since people are connected to at most
few thousands.

When the graph has few connections compared to the number of nodes we
say that we have a *sparse graph*. On the opposite, if we have almost
complete graphs we say we have a *dense graph*.

The space complexity of adjacency matrix is *O(|V|^2^)*, where |V| is
the number of vertices/nodes.

=== Adjacency List

Another way to represent a graph is using an adjacency list. This time
instead of using an array (matrix) we use a list.

image:extracted-media/media/image48.png[image,width=528,height=237]

Figure 32 – Graph represented as an Adjacency List.

Body

== Adding a vertex

Body text

== Adding an edge

Body text

== Querying Adjacency

Body text

== Deleting a vertex

Body text

== Deleting an edge

Body text

== Graph Complexity

Graph search has its own chapter

= Summary

Body text

4

[[_Toc525822218]]Learning Fast Sorting Algorithms

Introduction.

* _______
Topic 1
_______
* _______
Topic 2
_______
* _______
Topic 3
_______

= Avoiding Slow Sorting Algorithms

Iterate and expand on the sub-topic.

== Selection Sort

Body text

== Bubble Sort

Body text

== Insertion Sort

Body text

= Understanding Efficient Sorting Algorithms

Iterate and expand on the sub-topic.
https://en.wikipedia.org/wiki/Sorting_algorithm[https://en.wikipedia.org/wiki/Sorting_algorithm#Comparison_of_algorithms]

== Merge Sort

Stable but uses additional memory, Block merge sort uses constant memory
https://en.wikipedia.org/wiki/Block_sort

The entire input must be iterated through, and this must occur O(log(n))
times (the input can only be halved O(log(n)) times). n items iterated
log(n) times gives O(n log(n)).

== Quick Sort

Body text

A binary search tree is a dynamic version of what happens during
quicksort.

== Tim Sort

Stable but use additional memory

== Heapsort

Body text

== Radix Sort

t's been proven that no comparison sort can operate faster than this.
Only sorts that rely on a special property of the input such as radix
sort can beat this complexity. The constant factors of mergesort are
typically not that great though so algorithms with worse complexity can
often take less time.
https://softwareengineering.stackexchange.com/a/297161/106607

A trie is a dynamic version of what happens during radix sort.

= Summary

Body text

5

[[_Toc525822222]]Searching Efficiently

Introduction.

* _______
Topic 1
_______
* _______
Topic 2
_______
* _______
Topic 3
_______

= Linear Search

Iterate and expand on the sub-topic.

== Linear Search

Body text

== Binary Search

Body text

== Sub-topic

Body text

= Searching in a Graph

Iterate and expand on the sub-topic.

== Depth First Search (DFS)

Body text

== Breadth First Search (BFS)

Body text

== Sub-topic

Body text

= Shortest Path with Dijkstra

Iterate and expand on the sub-topic.

== Sub-topic

Body text

== Sub-topic

Body text

== Sub-topic

Body text

= Summary

Body text

5

[[_Toc525822227]]Balancing Binary Search Trees for Max Performance

Introduction.

* _______
Topic 1
_______
* _______
Topic 2
_______
* _______
Topic 3
_______

= Tree Rotations

Iterate and expand on the sub-topic.

== Left Rotation

Body text

== Right Rotation

Body text

== Left-Right Rotation

Body text

== Right-Left Rotation

Body text

= AVL Tree

Iterate and expand on the sub-topic.

== Insertion

Body text

== Search by Value

Body text

== Deletion

Body text

= Summary

Body text

0

[[_Toc525822231]]Algorithmic Thinking

Introduction. Firstly, address your headings. Next introduce _yourself_
to the chapter. Start with the topic. What is it. Tell them why it’s
useful. Now explain your chapter structure. What key milestones will hit
throughout the chapter.

Reiterate the chapter structure with bullet points:

* _______
Topic 1
_______
* _______
Topic 2
_______
* _______
Topic 3
_______

= Algorithmic Paradigms

Write your heading. Your headings should generally always try to tell
the reader what they will be _doing_ with the section. A useful device
are “gerund” words. These are –ing words, like “Implementing”,
“Building, “Creating”, “Programming”, “Testing.

Iterate and expand on the sub-topic. Explain what the sub-topic is.
Where does it fit in to the wider topic? Explain the key steps/subtopics
the reader will perform.

Towards the end, outline any prerequisites the reader will need – will
they need anything new installed? Will they want any specific files or
programmes open?

== Brute Force

Body text. Now outline the key steps needed to perform the topic.

Linear search

== Greedy

Body text,

A Dijkstra Algorithm - finding shortest path to all graph vertices

== Divide and Conquer

Binary Search,
https://github.com/trekhleb/javascript-algorithms#algorithms-by-paradigm

B Merge Sort

B Quicksort

B Tree Depth-First Search (DFS)

B Graph Depth-First Search (DFS)

== Dynamic Programming

Binary Search,

= Topic

Iterate and expand on the sub-topic.

== Sub-topic

Body text

== Sub-topic

Body text

== Sub-topic

Body text

= Topic

Iterate and expand on the sub-topic.

== Sub-topic

Body text

== Sub-topic

Body text

== Sub-topic

Body text

= Summary

Body text

0

[[_Toc525822236]]Stepping up your game with Advanced Data Structures

Introduction.

* _______
Topic 1
_______
* _______
Topic 2
_______
* _______
Topic 3
_______

= Heap

Iterate and expand on the sub-topic.

== Insert

Body text

== Heapify

Body text

== Find max/min

Body text

== Extract max/min

Body text

== Increase Key

Body text

== Delete

Body text

== Merge

Body text

= Tries

Iterate and expand on the sub-topic.
https://github.com/trekhleb/javascript-algorithms/tree/master/src/data-structures/trie

Why Trie? :-

1.  With Trie, we can insert and find strings in O(L) time where L
represent the length of a single word. This is obviously faster that
BST. This is also faster than Hashing because of the ways it is
implemented. We do not need to compute any hash function. No collision
handling is required (like we do in open addressing and separate
chaining)
2.  Another advantage of Trie is, we can easily print all words in
alphabetical order which is not easily possible with hashing.
3.  We can efficiently do prefix search (or auto-complete) with Trie.

Issues with Trie :-

The main disadvantage of tries is that they need lot of memory for
storing the strings. For each node we have too many node pointers(equal
to number of characters of the alphabet), If space is concern, then
Ternary Search Tree can be preferred for dictionary implementations. In
Ternary Search Tree, time complexity of search operation is O(h) where h
is height of the tree. Ternary Search Trees also supports other
operations supported by Trie like prefix search, alphabetical order
printing and nearest neighbor search.

https://thenextcode.wordpress.com/2015/04/12/trie-vs-bst-vs-hashtable/

https://en.wikipedia.org/wiki/Deterministic_acyclic_finite_state_automaton

http://jayant7k.blogspot.com/2011/06/data-structures-trie.html

The final conclusion is regarding tries data structure is that they are
faster but require huge memory for storing the strings.

Binary Tree, BST, Heaps, Tries, …

Body text
https://en.wikipedia.org/wiki/Heap_(data_structure)[https://en.wikipedia.org/wiki/Heap_(data_structure)#Comparison_of_theoretic_bounds_for_variants]

== Applications

Body text

== Insert word

Body text

== Suggesting next characters

Body text

== Delete Word

Body text

Summary

Body text

Code

_const_ Node = require('./node');

_/**_

_* Doubly linked list that keeps track of_

_* the last and first element_

_*/_

_class_ LinkedList \{

_constructor_() \{

this.first = null; // head/root element

_this_.last = null; _// last element of the list_

_this_.size = 0; _// total number of elements in the list_

}

}

===== Testing.ts

// code

Code end

High 0

Highend

$ curl –-path-as-is http://localhost:3000/../test.txt

Big O Cheatsheet

[cols=",,,,,,,,,",options="header",]
|=======================================================================
|Data Structure |Searching by |Inserting at the |Deleting from the
|Space Complexity | | | | |
| |_Index/Key_ |_Value_ |_start_ |_middle_ |_end_ |_start_ |_middle_
|_end_ |

|Array |*O(1)* |*O(n)* |*O(n)* |*O(n)* |*O(1)* |*O(n)* |*O(n)* |*O(1)*
|*O(n)*

|Linked List (singly) |*O(n)* |*O(n)* |*O(1)* |*O(n)* |*O(1)* |*O(1)*
|*O(n)* |*O(n)* |*O(n)*

|Linked List (doubly) |*O(n)* |*O(n)* |*O(1)* |*O(n)* |*O(1)* |*O(1)*
|*O(n)* |*O(1)* |*O(n)*

|Stack |- |- |- |- |*O(1)* |- |- |*O(1)* |*O(n)*

|Queue (w/array) |- |- |*O(n)* |- |- |- |- |*O(1)* |*O(n)*

|Queue (w/list) |- |- |*O(1)* |- |- |- |- |*O(1)* |*O(n)*
|=======================================================================

[cols=",,,,,",options="header",]
|=======================================================================
|Data Structure |Searching by |Insert |Delete |Space Complexity |
| |_Index/Key_ |_Value_ | | |

|Binary Search Tree (unbalanced) |- |*O(n)* |*O(n)* |*O(n)* |*O(n)*

|Binary Search Tree (balanced: AVL tree) |- |*O(log n)* |*O(log n)*
|*O(log n)* |*O(n)*

|Hash Map (Imperfect) |*O(n)* |*O(n)* |*O(n)* |*O(n)* |*O(n)*

|Hash Map (optimized) |*O(1)** |*O(n)* |*O(1)** |*O(1)** |*O(n)*

|Tree Map |*O(log n)* |*O(n)* |*O(log n)* |*O(log n)* |*O(n)*

|Set (using Hash Map) |- |*O(1)** |*O(1)** |*O(1)** |*O(n)*

|Set (using Tree Map) |- |*O(log n)* |*O(log n)* |*O(log n)* |*O(n)*
|=======================================================================

* = Amortized time. E.g. rehashing might affect run time

image:extracted-media/media/image49.jpeg[image,width=528,height=186]

Implementing an LRU Cache with HashMap

Discards the least recently used items first. 

https://leetcode.com/problems/lru-cache/description/

TODO: Compare content with:

* https://adrianmejia.com/blog/2018/04/28/data-structures-time-complexity-for-beginners-arrays-hashmaps-linked-lists-stacks-queues-tutorial/[https://adrianmejia.com/blog/2018/04/28/data-structures-time-complexity-for-beginners-arrays-hashmaps-linked-lists-stacks-queues-tutorial/#Stacks]
* https://leetcode.com/explore/learn/
* https://github.com/trekhleb/javascript-algorithms
* Compare with: Data Structures and Algorithms.pdf by Lydia Hallie
* Cracking code interviews
* Grokking Algorithms
* CS Distilled
* Create poster like: http://bigocheatsheet.com/, http://bigoref.com/,
* Princeton
** https://introcs.cs.princeton.edu/java/11cheatsheet/
